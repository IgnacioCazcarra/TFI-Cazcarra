{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f49b1dc",
   "metadata": {},
   "source": [
    "### A lot of duplicated code with no reuse whatsoever. Not good but way faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353c0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30504272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.detection.prediction_utils import get_model, filter_predictions, visualize_boxes\n",
    "from src.slides_utils.slides_utils import *\n",
    "from src.line_detection.hough import get_tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31fa61d",
   "metadata": {},
   "source": [
    "## Instance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c63b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODELS = \"/home/nacho/TFI-Cazcarra/models\"\n",
    "\n",
    "test_df = pd.read_csv(\"/home/nacho/TFI-Cazcarra/data/csv/test_diagramas_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a74a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet = get_model(object_to_predict=\"tablas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn = choose_model(model_name=\"fasterrcnn\", object_to_predict=\"tablas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = torch.hub.load('ultralytics/yolov5', 'custom', os.path.join(PATH_YOLO, \"exp7\", \"weights\", \"best_tablas.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7d3e3",
   "metadata": {},
   "source": [
    "## Calculo las predicciones de las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720c8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_to_search = [\"/home/nacho/TFI-Cazcarra/data/csv/test_diagramas_2023.csv\"]\n",
    "transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d7abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target(tablas):\n",
    "    return {\"boxes\": torch.Tensor(tablas), \"labels\": torch.IntTensor([1]*len(tablas))}\n",
    "\n",
    "def gen_pred(tablas_boxes, tablas_scores):\n",
    "    return {\"boxes\": tablas_boxes, \"scores\": tablas_scores, \"labels\": torch.IntTensor([1]*len(tablas_boxes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a621dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_torch(model, test_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img)\n",
    "        tablas, _ = get_tablas(img_path, where_to_search)\n",
    "        with torch.no_grad():\n",
    "            tablas_pred = model([img_tensor])[1][0]\n",
    "        tablas_boxes, tablas_scores = filter_predictions(tablas_pred, nms_threshold=0.5, score_threshold=0.49)\n",
    "        preds.append(gen_pred(tablas_boxes, tablas_scores))\n",
    "        target.append(gen_target(tablas))\n",
    "\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4897d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_yolo(model, test_df):\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tablas, _ = get_tablas(img_path, where_to_search)\n",
    "        tablas_pred = model(img)\n",
    "\n",
    "        pred = {\"boxes\": tablas_pred.xyxy[0][:, :4], \"scores\": tablas_pred.xyxy[0][:, 4]}\n",
    "        tablas_boxes, tablas_scores = filter_predictions(pred, nms_threshold=0.5, score_threshold=0.49)\n",
    "        \n",
    "        preds.append(gen_pred(tablas_boxes, tablas_scores))\n",
    "        target.append(gen_target(tablas))\n",
    "        \n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63da16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_torch(faster_rcnn, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9983073",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_yolo(yolo, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d1f72",
   "metadata": {},
   "source": [
    "## Calculo las predicciones para las cardinalidades\n",
    "NOTA: Como las labels no importan, las seteamos todas a 1. Lo único que necesita el sistema es saber donde están las cardinalidades, no de qué tipo son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2303bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet = torch.jit.load(PATH_MODELS+\"/\"+\"model_best_cardinalidades_retinanet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = torch.hub.load('ultralytics/yolov5', 'custom', os.path.join(PATH_YOLO, \"exp9\", \"weights\", \"best_cardinalidades_retrained.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_to_search = [\"/home/nacho/TFI-Cazcarra/data/tiles/test_cardinalidades_2023_fixed.csv\"]\n",
    "transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target_card(boxes_gt, label_gt):\n",
    "    return {\"boxes\": boxes_gt, \"labels\": label_gt}\n",
    "\n",
    "def gen_pred_card(boxes, scores, labels):\n",
    "    return {\"boxes\": boxes, \"scores\": scores, \"labels\": labels}\n",
    "\n",
    "def filter_predictions2(predictions, score_threshold=0.5, nms_threshold=0.5):\n",
    "    boxes = predictions['boxes'][predictions['scores'] >= score_threshold]\n",
    "    scores = predictions['scores'][predictions['scores'] >= score_threshold]\n",
    "    labels = predictions['labels'][predictions['scores'] >= score_threshold]\n",
    "    valid_idx = torchvision.ops.nms(boxes, scores, nms_threshold)\n",
    "    return boxes[valid_idx], scores[valid_idx], labels[valid_idx]\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7748c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_torch(model, test_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    le_dict = {'muchos_opcional': 2,\n",
    "               'muchos_obligatorio': 1,\n",
    "               'uno_opcional': 3,\n",
    "               'uno_obligatorio': 4}\n",
    "    \n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img)\n",
    "        \n",
    "        boxes_gt = test_df[test_df.image_path==img_path][['xmin','ymin','xmax','ymax']].values\n",
    "        boxes_gt = torch.Tensor(boxes_gt)\n",
    "        label_gt = test_df[test_df.image_path==img_path]['label'].values\n",
    "        label_gt = torch.Tensor([le_dict[val] for val in label_gt])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            card_pred = model([img_tensor])[1][0]\n",
    "        card_boxes, card_scores, card_labels = filter_predictions2(card_pred, \n",
    "                                                                  nms_threshold=0.5, \n",
    "                                                                 score_threshold=0.3)\n",
    "        img = visualize_boxes(img, card_boxes, color=(255,0,0))\n",
    "        img = visualize_boxes(img, boxes_gt, color=(0,255,0))\n",
    "        display(img_path, img)\n",
    "        preds.append(gen_pred(card_boxes, card_scores))\n",
    "        target.append(gen_target(boxes_gt))\n",
    "\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b596582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_yolo(model, test_df):\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    le_dict = {'muchos_opcional': 2,\n",
    "           'muchos_obligatorio': 1,\n",
    "           'uno_opcional': 3,\n",
    "           'uno_obligatorio': 4}\n",
    "    \n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        card_pred = model(img)\n",
    "        w,h = img.size\n",
    "        boxes_gt = test_df[test_df.image_path==img_path][['xmin','ymin','xmax','ymax']].values\n",
    "        boxes_gt = torch.Tensor(boxes_gt)\n",
    "        label_gt = test_df[test_df.image_path==img_path]['label'].values\n",
    "        label_gt = torch.Tensor([le_dict[val]-1 for val in label_gt])\n",
    "        \n",
    "        pred = {\"boxes\": card_pred.xyxy[0][:, :4], \"scores\": card_pred.xyxy[0][:, 4], \n",
    "                \"labels\": card_pred.xyxy[0][:, 5]}\n",
    "\n",
    "        card_boxes, card_scores, card_labels = filter_predictions2(pred, nms_threshold=0.5, score_threshold=0.49)\n",
    "        \n",
    "        img = visualize_boxes(img, card_boxes, color=(255,0,0))\n",
    "        img = visualize_boxes(img, boxes_gt, color=(0,255,0))\n",
    "        display(img_path, img)\n",
    "        #Cambio esto y no le paso las labels a ver que pasa...\n",
    "        preds.append(gen_pred(card_boxes, card_scores))\n",
    "        target.append(gen_target(boxes_gt))\n",
    "        \n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52077d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/home/nacho/TFI-Cazcarra/data/tiles/test_cardinalidades_2023_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffab14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculate_metrics_torch(retinanet, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cfa708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculate_metrics_yolo(yolo, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1e1ad",
   "metadata": {},
   "source": [
    "## Lo mismo para tiles PERO calculo los scores para las imagenes enteras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc890b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/home/nacho/TFI-Cazcarra/data/csv/test_diagramas_2023.csv\")\n",
    "where_to_search = [\"/home/nacho/TFI-Cazcarra/data/csv/test_diagramas_2023.csv\"]\n",
    "transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa94497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_images2(img, boxes_per_tile):\n",
    "    img = np.array(img)\n",
    "    first_tile = next(iter(boxes_per_tile.keys()))\n",
    "    all_boxes = np.array([[]])\n",
    "    all_scores = np.array([])\n",
    "    all_labels = np.array([])\n",
    "    \n",
    "    for tile, prediction in boxes_per_tile.items():\n",
    "        coords_to_add = torch.Tensor(list(map(lambda i,j: i-j, literal_eval(tile), literal_eval(first_tile))))\n",
    "        boxes = torch.add(prediction['boxes'], coords_to_add, alpha=1).detach().numpy()\n",
    "        all_boxes = np.append(all_boxes, boxes)\n",
    "        all_scores = np.append(all_scores, prediction['scores'])\n",
    "        all_labels = np.append(all_labels, prediction['labels'])\n",
    "    return {\"boxes\": torch.from_numpy(all_boxes.reshape((-1,4))), \"scores\": torch.from_numpy(all_scores),\n",
    "            \"labels\": torch.from_numpy(all_labels)}\n",
    "\n",
    "\n",
    "def predict_tiles2(img, model, is_yolo, transform, min_size=600, max_size=1333):\n",
    "    tiles = slice_img_from_prediction(img, tile_size=None, tile_overlap=0.0, number_tiles=6)\n",
    "    preds_image = {}\n",
    "    with torch.no_grad():\n",
    "        for tile in tiles:\n",
    "            tile_img = img.crop(tile).convert(\"RGB\")\n",
    "            tensor_tile = transform(tile_img)\n",
    "            if not is_yolo:\n",
    "                predictions = model([tensor_tile])[1][0]\n",
    "            else:\n",
    "                predictions = model(tile_img)\n",
    "                predictions = {\"boxes\": predictions.xyxy[0][:, :4], \n",
    "                               \"scores\": predictions.xyxy[0][:, 4],\n",
    "                               \"labels\": predictions.xyxy[0][:, 5]}\n",
    "            preds_image[str(tile)] = predictions\n",
    "    unified_results = unify_images2(img=img, boxes_per_tile=preds_image)\n",
    "    return unified_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_torch(model, test_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    target = []\n",
    "    test_df = test_df[test_df['label']!=\"tabla\"]\n",
    "    le_dict = {'muchos_opcional': 2,\n",
    "               'muchos_obligatorio': 1,\n",
    "               'uno_opcional': 3,\n",
    "               'uno_obligatorio': 4}\n",
    "    \n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img)\n",
    "        \n",
    "        boxes_gt = test_df[test_df.image_path==img_path][['xmin','ymin','xmax','ymax']].values\n",
    "        boxes_gt = torch.Tensor(boxes_gt)\n",
    "        label_gt = test_df[test_df.image_path==img_path]['label'].values\n",
    "        label_gt = torch.Tensor([le_dict[val] for val in label_gt])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cardinalidades_pred = predict_tiles2(img, model=model, is_yolo=False, transform=transform)\n",
    "            card_boxes, card_scores, card_labels = filter_predictions2(cardinalidades_pred, nms_threshold=0.5, \n",
    "                                                                       score_threshold=0.3)       \n",
    "        \n",
    "        preds.append(gen_pred(card_boxes, card_scores))\n",
    "        target.append(gen_target(boxes_gt))\n",
    "\n",
    "        img = visualize_boxes(img, card_boxes, color=(255,0,0))\n",
    "        img = visualize_boxes(img, boxes_gt, color=(0,255,0))\n",
    "        display(img_path, img)\n",
    "        \n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_yolo_unified(model, test_df):\n",
    "    \n",
    "    test_df = test_df[test_df['label']!=\"tabla\"]\n",
    "    preds = []\n",
    "    target = []\n",
    "    \n",
    "    le_dict = {'muchos_opcional': 2,\n",
    "               'muchos_obligatorio': 1,\n",
    "               'uno_opcional': 3,\n",
    "               'uno_obligatorio': 4}\n",
    "        \n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        cardinalidades_pred = predict_tiles2(img, model=model, is_yolo=True, transform=transform)\n",
    "        cardinalidades_boxes, cardinalidades_scores, cardinalidades_labels = filter_predictions2(cardinalidades_pred, \n",
    "                                                                                                 nms_threshold=0.5, \n",
    "                                                                                                score_threshold=0.49)       \n",
    "        boxes_gt = test_df[test_df.image_path==img_path][['xmin','ymin','xmax','ymax']].values\n",
    "        boxes_gt = torch.Tensor(boxes_gt)\n",
    "        label_gt = test_df[test_df.image_path==img_path]['label'].values\n",
    "        label_gt = torch.Tensor([le_dict[val]-1 for val in label_gt])\n",
    "    \n",
    "        img = visualize_boxes(img, cardinalidades_boxes, color=(255,0,0))\n",
    "        img = visualize_boxes(img, boxes_gt, color=(0,255,0))\n",
    "        #display(img_path, img)\n",
    "        \n",
    "        preds.append(gen_pred(cardinalidades_boxes, cardinalidades_scores))\n",
    "        target.append(gen_target(boxes_gt))\n",
    "        \n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571bf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calculate_metrics_yolo_unified(yolo, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baebc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_torch(faster_rcnn, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da2e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
