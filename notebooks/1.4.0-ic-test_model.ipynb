{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9a2fe2",
   "metadata": {},
   "source": [
    "#### https://discuss.pytorch.org/t/how-to-give-more-importance-to-one-class/83588/5\n",
    "- Al faster rcnn le va mal con los \"label_opcional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9043805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.training_utils.training import get_model_instance_segmentation\n",
    "from src.training_utils.dataset import *\n",
    "from src.constants import *\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130ae7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.rpn import RPNHead\n",
    "\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16cb42f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_dict = get_encoder_dict(CLASSES_CSV)\n",
    "num_classes = len(le_dict)+1 \n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00766cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LOAD_MODEL = f\"/home/nacho/TFI-Cazcarra/data/models/model_best_cardinalidades_fasterrcnn.pt\"\n",
    "\n",
    "model = torch.jit.load(PATH_TO_LOAD_MODEL)\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(num_label, le_dict):\n",
    "    reversed_le_dict = {v:k for k,v in le_dict.items()}\n",
    "    return reversed_le_dict[num_label]\n",
    "\n",
    "def draw_bbox(img, xmin, ymin, xmax, ymax, score, label): \n",
    "    txt = get_class_name(label, le_dict) + ' ' + str(score)\n",
    "    img = cv2.putText(img, txt, (int(xmin), int(ymin)),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255), 1)\n",
    "\n",
    "    return cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), \n",
    "                         (255,0,0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"/home/nacho/TFI-Cazcarra/data/tiles/test_cardinalidades_linux_fixed.csv\")\n",
    "test_df['label_transformed'] = test_df['label'].apply(lambda x: le_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7977f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_path in test_df.image_path.unique()[:15]:\n",
    "    image = Image.open(test_path).convert('RGB')\n",
    "    tensor_image = T.ToTensor()(image)\n",
    "    predictions = model([tensor_image])\n",
    "#     for prediction in predictions:\n",
    "#         print(predictions)\n",
    "    prediction = predictions[1][0]\n",
    "    for box, score, label in zip(prediction['boxes'],prediction['scores'],prediction['labels']):\n",
    "        score = round(score.item(), 3)\n",
    "        label = label.item()\n",
    "        if score <= 0.4:\n",
    "            continue\n",
    "        xmin = box[0].item()\n",
    "        ymin = box[1].item()\n",
    "        xmax = box[2].item()\n",
    "        ymax = box[3].item()\n",
    "        print(xmin, ymin, xmax, ymax)\n",
    "        if isinstance(image, PIL.Image.Image):\n",
    "            image = draw_bbox(np.array(image), xmin, ymin, xmax, ymax, score, label)\n",
    "        else:\n",
    "            image = draw_bbox(image, xmin, ymin, xmax, ymax, score, label)\n",
    "    display(Image.fromarray(image)) if not isinstance(image, PIL.Image.Image) else display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae9350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe091ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor((1, 2))\n",
    "b = torch.tensor((1, 2))\n",
    "torch.sub(a, b, alpha=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9096ad",
   "metadata": {},
   "source": [
    "## imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ce37578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"/home/nacho/TFI-Cazcarra/data/tiles/train_cardinalidades_linux_fixed.csv\")\n",
    "train_df['label_transformed'] = train_df['label'].apply(lambda x: le_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1063b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['class_weight'] = train_df['label'].apply(lambda x: 0.5 if \"opcional\" in x else 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "016e35b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df['class_weight'] = train_df['label'].apply(lambda x: 0.5 if \"opcional\" in x else 0.25)\n",
    "\n",
    "class_weights = []\n",
    "for path in sorted(train_df['image_path'].unique()):\n",
    "    filtered = train_df[train_df['image_path']==path]\n",
    "    class_weight = max(filtered['class_weight'].values)\n",
    "    class_weights.append(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7908adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(weights=class_weights, num_samples=3*len(train_df['image_path'].unique()), \n",
    "                                replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c62e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
