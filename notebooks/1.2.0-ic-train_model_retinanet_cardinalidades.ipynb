{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bba64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df240e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.constants import *\n",
    "from src.training_utils.dataset import *\n",
    "from src.training_utils.training import train_model, get_model_instance_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60adafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b427622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{PATH}/data/tiles/train_cardinalidades_linux.csv\")\n",
    "test_df = pd.read_csv(f\"{PATH}/data/tiles/test_cardinalidades_linux.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le_dict = get_encoder_dict(CLASSES_CSV)\n",
    "# le_dict\n",
    "\n",
    "le_dict = {'muchos_opcional': 2,\n",
    "           'muchos_obligatorio': 1,\n",
    "           'uno_opcional': 3,\n",
    "           'uno_obligatorio': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label_transformed'] = train_df['label'].apply(lambda x: le_dict[x])\n",
    "test_df['label_transformed'] = test_df['label'].apply(lambda x: le_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(0.5))\n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506163d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = f\"{PATH}/data/tiles/image_slices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = len(le_dict)+1 \n",
    "\n",
    "dataset = PennFudanDataset(csv=train_df, images_dir=IMAGES_DIR)#, transforms=get_custom_transform(train=True))\n",
    "dataset_test = PennFudanDataset(csv=test_df, images_dir=IMAGES_DIR)#, transforms=get_custom_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a775bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_dataloader(dataset, batch_size=2, shuffle=True)\n",
    "data_loader_test = get_dataloader(dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52b21c",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee72b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6130a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_instance_segmentation(num_classes=num_classes, model_type=\"retinanet\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# override_path = f\"{PATH}/data/models/model_best_test.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ac49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    train_model(model=model, data_loader=data_loader, data_loader_test=data_loader_test, \n",
    "            num_epochs=epochs, device=device, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068dee8d",
   "metadata": {},
   "source": [
    "## Save model\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = model.__class__.__name__.lower()\n",
    "# PATH_TO_SAVE_MODEL = f\"{PATH}/data/models/model_{model_name}_final.pt\"\n",
    "\n",
    "# save_model(path_to_save, model, epoch, loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323302d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "\n",
    "def get_class_name(num_label, le_dict):\n",
    "    reversed_le_dict = {v:k for k,v in le_dict.items()}\n",
    "    return reversed_le_dict[num_label]\n",
    "\n",
    "def draw_bbox(img, xmin, ymin, xmax, ymax, score, label): \n",
    "    txt = get_class_name(label, le_dict) + ' ' + str(score)\n",
    "    img = cv2.putText(img, txt, (int(xmin), int(ymin)),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255), 1)\n",
    "\n",
    "    return cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), \n",
    "                         (255,0,0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83064e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12100ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset_test)):\n",
    "    tensor_image = dataset_test.__getitem__(i)[0]\n",
    "    to_pil = T.ToPILImage()\n",
    "    pil_image = to_pil(tensor_image)\n",
    "    predictions = model([tensor_image])\n",
    "    image = pil_image\n",
    "    for prediction in predictions:\n",
    "        for box, score, label in zip(prediction['boxes'],prediction['scores'],prediction['labels']):\n",
    "            score = round(score.item(), 3)\n",
    "            label = label.item()\n",
    "            if score < 0.5:\n",
    "                break\n",
    "            xmin = box[0].item()\n",
    "            ymin = box[1].item()\n",
    "            xmax = box[2].item()\n",
    "            ymax = box[3].item()\n",
    "            print(xmin, ymin, xmax, ymax)\n",
    "            if isinstance(image, PIL.Image.Image):\n",
    "                image = draw_bbox(np.array(image), xmin, ymin, xmax, ymax, score, label)\n",
    "            else:\n",
    "                image = draw_bbox(image, xmin, ymin, xmax, ymax, score, label)\n",
    "        display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3fb35",
   "metadata": {},
   "source": [
    "## Load the two final models & calculate AP for them\n",
    "- https://torchmetrics.readthedocs.io/en/stable/classification/average_precision.html\n",
    "- https://torchmetrics.readthedocs.io/en/stable/retrieval/map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c938b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_instance_segmentation(len(le_dict)+1, \"retinanet\")\n",
    "model_name = model.__class__.__name__.lower()\n",
    "PATH_TO_LOAD_MODEL = f\"/home/nacho/TFI-Cazcarra/data/models/model_{model_name}_final.pt\"\n",
    "\n",
    "model_obj = torch.load(PATH_TO_LOAD_MODEL)\n",
    "model.load_state_dict(model_obj['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8659fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En batch mata el kernel\n",
    "predictions = []\n",
    "targets = []\n",
    "for i in range(len(dataset_test)):\n",
    "    prediction = model([dataset_test.__getitem__(i)[0]])\n",
    "    predictions.append(prediction)\n",
    "    target = dataset_test.__getitem__(i)[1]\n",
    "    targets.append(dataset_test.__getitem__(i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [p[0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b565f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = MeanAveragePrecision(box_format=\"xyxy\", iou_type=\"bbox\", max_detection_thresholds=[100], class_metrics=False)\n",
    "metric.update(predictions, targets)\n",
    "pprint(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d9416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
