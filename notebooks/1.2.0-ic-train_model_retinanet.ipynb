{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bba64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df240e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.constants import *\n",
    "from src.training_utils.dataset import *\n",
    "from src.training_utils.training import train_model, get_model_instance_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60adafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b427622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/nacho/TFI-Cazcarra/data/csv/augmented_train_diagramas.csv\", \n",
    "                       header=None)\n",
    "train_df.columns = ['image_path', 'xmin', 'ymin', 'xmax', 'ymax', 'label']\n",
    "\n",
    "test_df = pd.read_csv(\"/home/nacho/TFI-Cazcarra/data/csv/augmented_test_diagramas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a99e7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tabla': 3,\n",
       " 'muchos_opcional': 2,\n",
       " 'muchos_obligatorio': 1,\n",
       " 'uno_opcional': 5,\n",
       " 'uno_obligatorio': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_dict = get_encoder_dict(CLASSES_CSV)\n",
    "le_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8e866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label_transformed'] = train_df['label'].apply(lambda x: le_dict[x])\n",
    "test_df['label_transformed'] = test_df['label'].apply(lambda x: le_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ca9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41b6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = len(le_dict)+1 \n",
    "\n",
    "dataset = PennFudanDataset(csv=train_df, images_dir=IMAGES_DIR, transforms=get_custom_transform(train=True))\n",
    "dataset_test = PennFudanDataset(csv=test_df, images_dir=IMAGES_DIR, transforms=get_custom_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a775bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_dataloader(dataset, batch_size=2, shuffle=True)\n",
    "data_loader_test = get_dataloader(dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52b21c",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee72b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6130a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nacho/TFI-Cazcarra/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/nacho/TFI-Cazcarra/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancing model retinanet. Trainable parameters: 33792599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RetinaNet(\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelP6P7(\n",
       "        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): AnchorGenerator()\n",
       "  (head): RetinaNetHead(\n",
       "    (classification_head): RetinaNetClassificationHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 819, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (regression_head): RetinaNetRegressionHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (bbox_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_instance_segmentation(num_classes=num_classes, model_type=\"retinanet\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f0bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# override_path = f\"{PATH}/data/models/model_best_test.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ac49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/14]  eta: 0:04:25  lr: 0.000389  loss: 2.5516 (2.5516)  classification: 1.7330 (1.7330)  bbox_regression: 0.8186 (0.8186)  time: 18.9361  data: 0.0577\n",
      "Epoch: [0]  [10/14]  eta: 0:01:15  lr: 0.004232  loss: 1.6950 (1.9680)  classification: 0.9899 (1.2402)  bbox_regression: 0.7334 (0.7277)  time: 18.7758  data: 0.0713\n",
      "Epoch: [0]  [13/14]  eta: 0:00:18  lr: 0.005000  loss: 1.6222 (1.8724)  classification: 0.9772 (1.1840)  bbox_regression: 0.6451 (0.6885)  time: 18.4050  data: 0.0720\n",
      "Epoch: [0] Total time: 0:04:17 (18.4054 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:37  model_time: 6.2376 (6.2376)  evaluator_time: 0.0231 (0.0231)  time: 6.2822  data: 0.0216\n",
      "Test:  [5/6]  eta: 0:00:06  model_time: 6.2376 (6.1263)  evaluator_time: 0.0168 (0.0191)  time: 6.1641  data: 0.0187\n",
      "Test: Total time: 0:00:36 (6.1642 s / it)\n",
      "Averaged stats: model_time: 6.2376 (6.1263)  evaluator_time: 0.0168 (0.0191)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n",
      "\n",
      "Best loss: 1.491\n",
      "Saving best model for epoch: 1\n",
      "\n",
      "Guardando...\n",
      "Modelo guardado en /home/nacho/TFI-Cazcarra/data/models/best_model_retinanet.pt\n",
      "Epoch: [1]  [ 0/14]  eta: 0:04:30  lr: 0.005000  loss: 1.9240 (1.9240)  classification: 1.2253 (1.2253)  bbox_regression: 0.6987 (0.6987)  time: 19.2934  data: 0.0872\n",
      "Epoch: [1]  [10/14]  eta: 0:01:12  lr: 0.005000  loss: 1.3322 (1.3608)  classification: 0.8330 (0.8334)  bbox_regression: 0.5181 (0.5275)  time: 18.1993  data: 0.0679\n",
      "Epoch: [1]  [13/14]  eta: 0:00:18  lr: 0.005000  loss: 1.3276 (1.3388)  classification: 0.7659 (0.7992)  bbox_regression: 0.5183 (0.5397)  time: 18.6432  data: 0.0703\n",
      "Epoch: [1] Total time: 0:04:21 (18.6435 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:36  model_time: 5.9659 (5.9659)  evaluator_time: 0.0156 (0.0156)  time: 6.0027  data: 0.0212\n",
      "Test:  [5/6]  eta: 0:00:05  model_time: 5.9659 (5.8936)  evaluator_time: 0.0132 (0.0155)  time: 5.9279  data: 0.0187\n",
      "Test: Total time: 0:00:35 (5.9281 s / it)\n",
      "Averaged stats: model_time: 5.9659 (5.8936)  evaluator_time: 0.0132 (0.0155)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.752\n",
      "\n",
      "Best loss: 1.337\n",
      "Saving best model for epoch: 2\n",
      "\n",
      "Guardando...\n",
      "Modelo guardado en /home/nacho/TFI-Cazcarra/data/models/best_model_retinanet.pt\n",
      "Epoch: [2]  [ 0/14]  eta: 0:04:23  lr: 0.005000  loss: 0.9402 (0.9402)  classification: 0.5401 (0.5401)  bbox_regression: 0.4001 (0.4001)  time: 18.8019  data: 0.0750\n",
      "Epoch: [2]  [10/14]  eta: 0:01:16  lr: 0.005000  loss: 1.1749 (1.1416)  classification: 0.6932 (0.6668)  bbox_regression: 0.4754 (0.4748)  time: 19.0511  data: 0.0721\n",
      "Epoch: [2]  [13/14]  eta: 0:00:18  lr: 0.005000  loss: 1.1749 (1.1664)  classification: 0.6774 (0.6685)  bbox_regression: 0.4957 (0.4979)  time: 18.9531  data: 0.0718\n",
      "Epoch: [2] Total time: 0:04:25 (18.9535 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:35  model_time: 5.9038 (5.9038)  evaluator_time: 0.0086 (0.0086)  time: 5.9333  data: 0.0209\n",
      "Test:  [5/6]  eta: 0:00:05  model_time: 5.9038 (5.8733)  evaluator_time: 0.0086 (0.0111)  time: 5.9031  data: 0.0187\n",
      "Test: Total time: 0:00:35 (5.9033 s / it)\n",
      "Averaged stats: model_time: 5.9038 (5.8733)  evaluator_time: 0.0086 (0.0111)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n",
      "\n",
      "Best loss: 1.1\n",
      "Saving best model for epoch: 3\n",
      "\n",
      "Guardando...\n",
      "Modelo guardado en /home/nacho/TFI-Cazcarra/data/models/best_model_retinanet.pt\n",
      "Epoch: [3]  [ 0/14]  eta: 0:04:26  lr: 0.005000  loss: 1.0237 (1.0237)  classification: 0.6061 (0.6061)  bbox_regression: 0.4176 (0.4176)  time: 19.0549  data: 0.0548\n",
      "Epoch: [3]  [10/14]  eta: 0:01:13  lr: 0.005000  loss: 1.0597 (1.0645)  classification: 0.6236 (0.6211)  bbox_regression: 0.4279 (0.4434)  time: 18.4014  data: 0.0710\n",
      "Epoch: [3]  [13/14]  eta: 0:00:18  lr: 0.005000  loss: 1.0266 (1.0278)  classification: 0.6061 (0.5958)  bbox_regression: 0.4177 (0.4320)  time: 18.1669  data: 0.0708\n",
      "Epoch: [3] Total time: 0:04:14 (18.1673 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:34  model_time: 5.7804 (5.7804)  evaluator_time: 0.0157 (0.0157)  time: 5.8172  data: 0.0211\n",
      "Test:  [5/6]  eta: 0:00:05  model_time: 5.7804 (5.7797)  evaluator_time: 0.0145 (0.0169)  time: 5.8152  data: 0.0186\n",
      "Test: Total time: 0:00:34 (5.8153 s / it)\n",
      "Averaged stats: model_time: 5.7804 (5.7797)  evaluator_time: 0.0145 (0.0169)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.520\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.539\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.845\n",
      "\n",
      "Best loss: 0.602\n",
      "Saving best model for epoch: 4\n",
      "\n",
      "Guardando...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en /home/nacho/TFI-Cazcarra/data/models/best_model_retinanet.pt\n",
      "Epoch: [4]  [ 0/14]  eta: 0:04:27  lr: 0.005000  loss: 1.3308 (1.3308)  classification: 0.7548 (0.7548)  bbox_regression: 0.5759 (0.5759)  time: 19.1151  data: 0.0757\n",
      "Epoch: [4]  [10/14]  eta: 0:01:17  lr: 0.005000  loss: 1.1997 (1.0494)  classification: 0.6639 (0.6001)  bbox_regression: 0.4659 (0.4493)  time: 19.4094  data: 0.0874\n",
      "Epoch: [4]  [13/14]  eta: 0:00:19  lr: 0.005000  loss: 1.1108 (1.0286)  classification: 0.6327 (0.5871)  bbox_regression: 0.4659 (0.4415)  time: 19.4526  data: 0.0809\n",
      "Epoch: [4] Total time: 0:04:32 (19.4535 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:37  model_time: 6.2453 (6.2453)  evaluator_time: 0.0396 (0.0396)  time: 6.3063  data: 0.0214\n",
      "Test:  [5/6]  eta: 0:00:06  model_time: 6.2453 (6.0490)  evaluator_time: 0.0154 (0.0202)  time: 6.0921  data: 0.0228\n",
      "Test: Total time: 0:00:36 (6.0923 s / it)\n",
      "Averaged stats: model_time: 6.2453 (6.0490)  evaluator_time: 0.0154 (0.0202)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.507\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.860\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.882\n",
      "Epoch: [5]  [ 0/14]  eta: 0:04:20  lr: 0.000500  loss: 0.9777 (0.9777)  classification: 0.5891 (0.5891)  bbox_regression: 0.3885 (0.3885)  time: 18.6112  data: 0.0477\n",
      "Epoch: [5]  [10/14]  eta: 0:01:16  lr: 0.000500  loss: 0.9777 (0.9806)  classification: 0.5891 (0.5538)  bbox_regression: 0.4145 (0.4268)  time: 19.0306  data: 0.0779\n",
      "Epoch: [5]  [13/14]  eta: 0:00:19  lr: 0.000500  loss: 0.9777 (1.0077)  classification: 0.5891 (0.5700)  bbox_regression: 0.4145 (0.4377)  time: 19.2163  data: 0.0799\n",
      "Epoch: [5] Total time: 0:04:29 (19.2173 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:35  model_time: 5.8773 (5.8773)  evaluator_time: 0.0161 (0.0161)  time: 5.9148  data: 0.0214\n",
      "Test:  [5/6]  eta: 0:00:05  model_time: 5.8773 (5.8930)  evaluator_time: 0.0130 (0.0162)  time: 5.9278  data: 0.0186\n",
      "Test: Total time: 0:00:35 (5.9280 s / it)\n",
      "Averaged stats: model_time: 5.8773 (5.8930)  evaluator_time: 0.0130 (0.0162)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.553\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.872\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.903\n",
      "Epoch: [6]  [ 0/14]  eta: 0:04:20  lr: 0.000500  loss: 1.1909 (1.1909)  classification: 0.6690 (0.6690)  bbox_regression: 0.5220 (0.5220)  time: 18.5947  data: 0.0367\n",
      "Epoch: [6]  [10/14]  eta: 0:01:13  lr: 0.000500  loss: 1.0093 (0.9649)  classification: 0.5273 (0.5387)  bbox_regression: 0.4312 (0.4262)  time: 18.3168  data: 0.0732\n",
      "Epoch: [6]  [13/14]  eta: 0:00:18  lr: 0.000500  loss: 1.0093 (0.9963)  classification: 0.5273 (0.5562)  bbox_regression: 0.4330 (0.4401)  time: 18.6643  data: 0.0714\n",
      "Epoch: [6] Total time: 0:04:21 (18.6646 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:35  model_time: 5.8690 (5.8690)  evaluator_time: 0.0148 (0.0148)  time: 5.9051  data: 0.0212\n",
      "Test:  [5/6]  eta: 0:00:05  model_time: 5.8690 (5.8593)  evaluator_time: 0.0129 (0.0156)  time: 5.8935  data: 0.0186\n",
      "Test: Total time: 0:00:35 (5.8936 s / it)\n",
      "Averaged stats: model_time: 5.8690 (5.8593)  evaluator_time: 0.0129 (0.0156)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.549\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.486\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.462\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.921\n",
      "Epoch: [7]  [ 0/14]  eta: 0:04:23  lr: 0.000500  loss: 1.0883 (1.0883)  classification: 0.5539 (0.5539)  bbox_regression: 0.5344 (0.5344)  time: 18.8506  data: 0.1163\n",
      "Epoch: [7]  [10/14]  eta: 0:01:15  lr: 0.000500  loss: 1.0948 (1.0826)  classification: 0.6153 (0.5974)  bbox_regression: 0.4872 (0.4852)  time: 18.8515  data: 0.0755\n",
      "Epoch: [7]  [13/14]  eta: 0:00:19  lr: 0.000500  loss: 1.0871 (1.0179)  classification: 0.5711 (0.5676)  bbox_regression: 0.4661 (0.4503)  time: 19.0320  data: 0.0741\n",
      "Epoch: [7] Total time: 0:04:26 (19.0325 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:34  model_time: 5.7791 (5.7791)  evaluator_time: 0.0152 (0.0152)  time: 5.8159  data: 0.0215\n",
      "Test:  [5/6]  eta: 0:00:05  model_time: 5.7791 (5.9430)  evaluator_time: 0.0127 (0.0156)  time: 5.9773  data: 0.0187\n",
      "Test: Total time: 0:00:35 (5.9774 s / it)\n",
      "Averaged stats: model_time: 5.7791 (5.9430)  evaluator_time: 0.0127 (0.0156)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.898\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.549\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.921\n",
      "Epoch: [8]  [ 0/14]  eta: 0:03:24  lr: 0.000500  loss: 0.9306 (0.9306)  classification: 0.5835 (0.5835)  bbox_regression: 0.3471 (0.3471)  time: 14.6140  data: 0.0191\n",
      "Epoch: [8]  [10/14]  eta: 0:01:15  lr: 0.000500  loss: 1.0213 (0.9580)  classification: 0.5835 (0.5291)  bbox_regression: 0.4423 (0.4289)  time: 18.8512  data: 0.0874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8]  [13/14]  eta: 0:00:18  lr: 0.000500  loss: 1.0213 (0.9750)  classification: 0.5835 (0.5504)  bbox_regression: 0.4259 (0.4246)  time: 18.6902  data: 0.0789\n",
      "Epoch: [8] Total time: 0:04:21 (18.6923 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:37  model_time: 6.2161 (6.2161)  evaluator_time: 0.0227 (0.0227)  time: 6.2621  data: 0.0233\n",
      "Test:  [5/6]  eta: 0:00:06  model_time: 6.2161 (6.1017)  evaluator_time: 0.0137 (0.0172)  time: 6.1380  data: 0.0191\n",
      "Test: Total time: 0:00:36 (6.1382 s / it)\n",
      "Averaged stats: model_time: 6.2161 (6.1017)  evaluator_time: 0.0137 (0.0172)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.554\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.911\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.562\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.469\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.933\n",
      "Epoch: [9]  [ 0/14]  eta: 0:03:40  lr: 0.000500  loss: 1.0860 (1.0860)  classification: 0.5679 (0.5679)  bbox_regression: 0.5181 (0.5181)  time: 15.7687  data: 0.0183\n",
      "Epoch: [9]  [10/14]  eta: 0:01:14  lr: 0.000500  loss: 1.0860 (1.0110)  classification: 0.6046 (0.5615)  bbox_regression: 0.4401 (0.4495)  time: 18.6340  data: 0.0728\n",
      "Epoch: [9]  [13/14]  eta: 0:00:18  lr: 0.000500  loss: 0.9734 (0.9757)  classification: 0.5393 (0.5441)  bbox_regression: 0.4341 (0.4316)  time: 18.4314  data: 0.0780\n",
      "Epoch: [9] Total time: 0:04:18 (18.4328 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:36  model_time: 5.9676 (5.9676)  evaluator_time: 0.0234 (0.0234)  time: 6.0133  data: 0.0222\n",
      "Test:  [5/6]  eta: 0:00:06  model_time: 5.9676 (5.9857)  evaluator_time: 0.0126 (0.0167)  time: 6.0213  data: 0.0188\n",
      "Test: Total time: 0:00:36 (6.0214 s / it)\n",
      "Averaged stats: model_time: 5.9676 (5.9857)  evaluator_time: 0.0126 (0.0167)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.551\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.909\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.933\n",
      "Epoch: [10]  [ 0/14]  eta: 0:03:38  lr: 0.000050  loss: 1.0444 (1.0444)  classification: 0.5762 (0.5762)  bbox_regression: 0.4681 (0.4681)  time: 15.6185  data: 0.0170\n"
     ]
    }
   ],
   "source": [
    "if train:\n",
    "    train_model(model=model, data_loader=data_loader, data_loader_test=data_loader_test, \n",
    "            num_epochs=epochs, device=device, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068dee8d",
   "metadata": {},
   "source": [
    "## Save model\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = model.__class__.__name__.lower()\n",
    "# PATH_TO_SAVE_MODEL = f\"{PATH}/data/models/model_{model_name}_final.pt\"\n",
    "\n",
    "# save_model(path_to_save, model, epoch, loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323302d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "\n",
    "def get_class_name(num_label, le_dict):\n",
    "    reversed_le_dict = {v:k for k,v in le_dict.items()}\n",
    "    return reversed_le_dict[num_label]\n",
    "\n",
    "def draw_bbox(img, xmin, ymin, xmax, ymax, score, label): \n",
    "    txt = get_class_name(label, le_dict) + ' ' + str(score)\n",
    "    img = cv2.putText(img, txt, (int(xmin), int(ymin)),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255), 1)\n",
    "\n",
    "    return cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), \n",
    "                         (255,0,0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83064e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12100ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset_test)):\n",
    "    tensor_image = dataset_test.__getitem__(i)[0]\n",
    "    to_pil = T.ToPILImage()\n",
    "    pil_image = to_pil(tensor_image)\n",
    "    predictions = model([tensor_image])\n",
    "    image = pil_image\n",
    "    for prediction in predictions:\n",
    "        for box, score, label in zip(prediction['boxes'],prediction['scores'],prediction['labels']):\n",
    "            score = round(score.item(), 3)\n",
    "            label = label.item()\n",
    "            if score < 0.5:\n",
    "                break\n",
    "            xmin = box[0].item()\n",
    "            ymin = box[1].item()\n",
    "            xmax = box[2].item()\n",
    "            ymax = box[3].item()\n",
    "            print(xmin, ymin, xmax, ymax)\n",
    "            if isinstance(image, PIL.Image.Image):\n",
    "                image = draw_bbox(np.array(image), xmin, ymin, xmax, ymax, score, label)\n",
    "            else:\n",
    "                image = draw_bbox(image, xmin, ymin, xmax, ymax, score, label)\n",
    "        display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3fb35",
   "metadata": {},
   "source": [
    "## Load the two final models & calculate AP for them\n",
    "- https://torchmetrics.readthedocs.io/en/stable/classification/average_precision.html\n",
    "- https://torchmetrics.readthedocs.io/en/stable/retrieval/map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c938b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_instance_segmentation(len(le_dict)+1, \"retinanet\")\n",
    "model_name = model.__class__.__name__.lower()\n",
    "PATH_TO_LOAD_MODEL = f\"/home/nacho/TFI-Cazcarra/data/models/model_{model_name}_final.pt\"\n",
    "\n",
    "model_obj = torch.load(PATH_TO_LOAD_MODEL)\n",
    "model.load_state_dict(model_obj['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8659fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En batch mata el kernel\n",
    "predictions = []\n",
    "targets = []\n",
    "for i in range(len(dataset_test)):\n",
    "    prediction = model([dataset_test.__getitem__(i)[0]])\n",
    "    predictions.append(prediction)\n",
    "    target = dataset_test.__getitem__(i)[1]\n",
    "    targets.append(dataset_test.__getitem__(i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [p[0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b565f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = MeanAveragePrecision(box_format=\"xyxy\", iou_type=\"bbox\", max_detection_thresholds=[100], class_metrics=False)\n",
    "metric.update(predictions, targets)\n",
    "pprint(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d9416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
