{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353c0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30504272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.detection.prediction_utils import choose_model, filter_predictions, visualize_boxes\n",
    "from src.line_detection.hough import get_tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31fa61d",
   "metadata": {},
   "source": [
    "## Instance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c63b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODELS = \"/home/nacho/TFI-Cazcarra/data/models\"\n",
    "PATH_YOLO = \"/home/nacho/TFI-Cazcarra/yolov3/runs/train\"\n",
    "\n",
    "test_df = pd.read_csv(\"/home/nacho/TFI-Cazcarra/data/csv/test_diagramas_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a74a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet = choose_model(model_name=\"retinanet\", object_to_predict=\"tablas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn = choose_model(model_name=\"fasterrcnn\", object_to_predict=\"tablas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = torch.hub.load('ultralytics/yolov5', 'custom', os.path.join(PATH_YOLO, \"exp7\", \"weights\", \"best_tablas.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7d3e3",
   "metadata": {},
   "source": [
    "## Calculo las predicciones de las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_to_search = [\"/home/nacho/TFI-Cazcarra/data/csv/test_diagramas_2023.csv\"]\n",
    "transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2d7abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target(tablas):\n",
    "    return {\"boxes\": torch.Tensor(tablas), \"labels\": torch.IntTensor([1]*len(tablas))}\n",
    "\n",
    "def gen_pred(tablas_boxes, tablas_scores):\n",
    "    return {\"boxes\": tablas_boxes, \"scores\": tablas_scores, \"labels\": torch.IntTensor([1]*len(tablas_boxes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_torch(model, test_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img)\n",
    "        tablas, _ = get_tablas(img_path, where_to_search)\n",
    "        with torch.no_grad():\n",
    "            tablas_pred = model([img_tensor])[1][0]\n",
    "        tablas_boxes, tablas_scores = filter_predictions(tablas_pred, nms_threshold=0.5, score_threshold=0.49)\n",
    "        preds.append(gen_pred(tablas_boxes, tablas_scores))\n",
    "        target.append(gen_target(tablas))\n",
    "\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4897d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_yolo(model, test_df):\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        tablas, _ = get_tablas(img_path, where_to_search)\n",
    "        tablas_pred = model(img)\n",
    "\n",
    "        pred = {\"boxes\": tablas_pred.xyxy[0][:, :4], \"scores\": tablas_pred.xyxy[0][:, 4]}\n",
    "        tablas_boxes, tablas_scores = filter_predictions(pred, nms_threshold=0.5, score_threshold=0.49)\n",
    "        \n",
    "        preds.append(gen_pred(tablas_boxes, tablas_scores))\n",
    "        target.append(gen_target(tablas))\n",
    "        \n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63da16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_torch(faster_rcnn, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_torch(retinanet, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9983073",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics_yolo(yolo, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d1f72",
   "metadata": {},
   "source": [
    "## Calculo las predicciones para las cardinalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2303bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por ahora los modelos estÃ¡n en path diferentes. TODO: HabrÃ­a que unificar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nacho/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-2-8 Python-3.8.10 torch-1.13.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 261 layers, 61513585 parameters, 0 gradients, 154.6 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# retinanet = choose_model(model_name=\"retinanet\", object_to_predict=\"cardinalidades\")\n",
    "faster_rcnn = choose_model(model_name=\"fasterrcnn\", object_to_predict=\"cardinalidades\")\n",
    "yolo = torch.hub.load('ultralytics/yolov5', 'custom', os.path.join(PATH_YOLO, \"exp3\", \"weights\", \"best_cardinalidades.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569e3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_to_search = [\"/home/nacho/TFI-Cazcarra/data/tiles/test_cardinalidades_2023_fixed.csv\"]\n",
    "transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0de5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target_card(boxes_gt, label_gt):\n",
    "    return {\"boxes\": boxes_gt, \"labels\": label_gt}\n",
    "\n",
    "def gen_pred_card(boxes, scores, labels):\n",
    "    return {\"boxes\": boxes, \"scores\": scores, \"labels\": labels}\n",
    "\n",
    "def filter_predictions2(predictions, score_threshold=0.5, nms_threshold=0.5):\n",
    "    boxes = predictions['boxes'][predictions['scores'] >= score_threshold]\n",
    "    scores = predictions['scores'][predictions['scores'] >= score_threshold]\n",
    "    labels = predictions['labels'][predictions['scores'] >= score_threshold]\n",
    "    valid_idx = torchvision.ops.nms(boxes, scores, nms_threshold)\n",
    "    return boxes[valid_idx], scores[valid_idx], labels[valid_idx]\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7748c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_torch(model, test_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    le_dict = {'muchos_opcional': 2,\n",
    "               'muchos_obligatorio': 1,\n",
    "               'uno_opcional': 3,\n",
    "               'uno_obligatorio': 4}\n",
    "    \n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(img)\n",
    "        \n",
    "        boxes_gt = test_df[test_df.image_path==img_path][['xmin','ymin','xmax','ymax']].values\n",
    "        boxes_gt = torch.Tensor(boxes_gt)\n",
    "        label_gt = test_df[test_df.image_path==img_path]['label'].values\n",
    "        label_gt = torch.Tensor([le_dict[val] for val in label_gt])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            card_pred = model([img_tensor])[1][0]\n",
    "        card_boxes, card_scores, card_labels = filter_predictions2(card_pred, \n",
    "                                                                  nms_threshold=0.5, \n",
    "                                                     score_threshold=0.49)\n",
    "        preds.append(gen_pred_card(card_boxes, card_scores, card_labels))\n",
    "        target.append(gen_target_card(boxes_gt, label_gt))\n",
    "\n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b596582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_yolo(model, test_df):\n",
    "    preds = []\n",
    "    target = []\n",
    "\n",
    "    le_dict = {'muchos_opcional': 2,\n",
    "           'muchos_obligatorio': 1,\n",
    "           'uno_opcional': 3,\n",
    "           'uno_obligatorio': 4}\n",
    "    \n",
    "    for img_path in tqdm(test_df.image_path.unique()):\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        card_pred = model(img)\n",
    "        w,h = img.size\n",
    "        boxes_gt = test_df[test_df.image_path==img_path][['xmin','ymin','xmax','ymax']].values\n",
    "        boxes_gt = torch.Tensor(boxes_gt)\n",
    "        label_gt = test_df[test_df.image_path==img_path]['label'].values\n",
    "        label_gt = torch.Tensor([le_dict[val]-1 for val in label_gt])\n",
    "        \n",
    "        pred = {\"boxes\": card_pred.xyxy[0][:, :4], \"scores\": card_pred.xyxy[0][:, 4], \n",
    "                \"labels\": card_pred.xyxy[0][:, 5]}\n",
    "\n",
    "        card_boxes, card_scores, card_labels = filter_predictions2(pred, nms_threshold=0.5, score_threshold=0.49)\n",
    "        \n",
    "        img = visualize_boxes(img, card_boxes, color=(255,0,0))\n",
    "        img = visualize_boxes(img, boxes_gt, color=(0,255,0))\n",
    "        #display(img_path, img)\n",
    "        #Cambio esto y no le paso las labels a ver que pasa...\n",
    "        preds.append(gen_pred(card_boxes, card_scores))\n",
    "        target.append(gen_target(boxes_gt))\n",
    "        \n",
    "    metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "    metric.update(preds, target)\n",
    "    result = metric.compute()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52077d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/home/nacho/TFI-Cazcarra/data/tiles/test_cardinalidades_2023_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ffab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_metrics_torch(faster_rcnn, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7cfa708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [01:52<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': tensor(0.24659),\n",
      " 'map_50': tensor(0.60959),\n",
      " 'map_75': tensor(0.12940),\n",
      " 'map_large': tensor(-1.),\n",
      " 'map_medium': tensor(0.39842),\n",
      " 'map_per_class': tensor(-1.),\n",
      " 'map_small': tensor(0.22590),\n",
      " 'mar_1': tensor(0.07535),\n",
      " 'mar_10': tensor(0.36442),\n",
      " 'mar_100': tensor(0.39695),\n",
      " 'mar_100_per_class': tensor(-1.),\n",
      " 'mar_large': tensor(-1.),\n",
      " 'mar_medium': tensor(0.48319),\n",
      " 'mar_small': tensor(0.38249)}\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics_yolo(yolo, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53c10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc890b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
